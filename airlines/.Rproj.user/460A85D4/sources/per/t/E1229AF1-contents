---
title: "Sds2 Project"
author: "Giacomo Maretto"
date: "09 gennaio 2019"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r, echo=FALSE,include=FALSE}
#install.packages("rjags","coda","Epi","lme4","pixmap","sp")
library(ggplot2)
library(ggfortify)
library(ggpubr)
library("ggmcmc")
library(rjags)
library(ggplot2)
library(knitr)
library(pander)
library(lattice)
airline <- read.table("http://www.uta.fi/sis/mtt/mttts12/jags/airline.txt",h=T,sep="")
set.seed(123)
```
# Airlines Fatalities

## Introduction 


In this project we are analyzing data collected from 1976 to 2001 about airline fatal accidents by the International Civil Aviation Organization in Montreal , Canada (www.icao.int).

Our goal is to get a good prediction about future fatalitis through a bayesian approach.

Our data is structured with four columns, year, fatal, miles, rate.

"Passenger miles" are in units of $10^{11}$ and the "accident rate" is the number of fatal accidents per $10^{11}$ passenger miles.


```{r, echo=FALSE}
airline$year1975= NULL
pander(airline) # the column fatal which contains the annual number of fatalities.

```
__________________________________________________
### Following three descriptive time series plot respectively about the number of fatal accidents, the miles flown and the accident rate per each year.


```{r, echo=FALSE}
 ################################ 
#A closer inspection of the number of fatal airline crashes can be dome by:
par(mfrow=c(1,2))
with(airline, plot( year, fatal, pch=16, type="b", ylim=c(0,32), bty="n" ) )
with(airline, plot( year, rate, pch=16, type="b", ylim=c(0,7), bty="n" ) )

theme_set(theme_classic())
theme_set(theme_bw())# Plot 
#autoplot(airline$year) + labs(title="AirFatal") + theme(plot.title = element_text(hjust=0.5))

# Allow Default X Axis Labels
p = ggplot(airline, aes(x=year)) + 
  geom_line(aes(y=fatal,x =year)) + 
  geom_point(aes(y=fatal,x=year))+
  labs(title="Time Series Chart", 
       subtitle="Returns fatal from 'Airlines' Dataset", 
       caption="Source: American Airlines", 
       y="Fatal")

p  + theme(axis.text.x = element_text(angle = 60, vjust = 0.5)) + scale_x_continuous("Year", labels = as.character(airline$year), breaks = airline$year)


```

```{r, echo=FALSE}
p = ggplot(airline, aes(x=year)) + 
  geom_line(aes(y=miles,x =year)) + 
  geom_point(aes(y=miles,x=year))+
  labs(title="Time Series Chart", 
       subtitle=" Miles per Year", 
       caption="Source: American Airlines", 
       y="Miles")

p  + theme(axis.text.x = element_text(angle = 60, vjust = 0.5)) + scale_x_continuous("Year", labels = as.character(airline$year), breaks = airline$year)
```

```{r, echo=FALSE}
p = ggplot(airline, aes(x=year)) + 
  geom_line(aes(y=rate,x =year)) + 
  geom_point(aes(y=rate,x=year))+
  labs(title="Time Series Chart", 
       subtitle="Rate per Year", 
       caption="Source: American Airlines", 
       y="Rate")

p  + theme(axis.text.x = element_text(angle = 60, vjust = 0.5)) + scale_x_continuous("Year", labels = as.character(airline$year), breaks = airline$year)
```

 started with the simplest model i could immagine, that simply all the years look the same.
This means that the number of fatal accidents in each year are independend with a $Poisson(\theta)$ distribution.
I set a non informative gamma prior distribution for $\theta$, that has $(\alpha, \beta) = (0.01,0.01)$


The model for the data is:


where $\theta$ is the expected number of fatal accidents in an year.
If the prior distribution for $\theta$ is $(\Gamma(\alpha,\beta))$ then the posterior distrubution is  $\Gamma(\alpha+n\bar y,\beta+n)$, where in this case $n=26$ and $n\bar y=  \sum^{26}_{i=1}y_i=634$
			$$y_i|\theta  \sim Poisson(\theta)$$
			with:
			
			$$\theta \sim Gamma(0.01,0.01)$$

## Posterior distribution 

The posterior distribution for $\theta$ is $\theta|y \sim \Gamma(634,26)$ and the conditional distribution of $\tilde{y}$ (the number of fatal accidents in  2002) is $Poisson(\theta)$.

So to simulate values of $\tilde{y}$ all we need to do is first generate a realized value form the posterior distribution of $\theta$ as the mean. Iterating this process will generate values of  $\tilde{y}$ from the posterior predictive distribution. What we are doing here is integrating numerically, using simulation, over the posterior distrobution in $\theta$.
We can simulate this easily in R.
```{r}
theta <- rgamma(1000, 634, 26 )
y.2002 <- rpois(1000,theta)
#hist( y.2002 )
plot( table(y.2002), type="h", lwd=5, lend=2, col=gray(0.5), bty="n", ylab="" )
hist(airline$fatal,col = "lightblue")

```

We can specify the model in R using the package rJags.

## First model
```{r}
cat( "model {
  for( i in 1:I ) {
    fatal[i] ~ dpois(mu)
    }
    mu ~ dgamma(0.01,0.01)
  }", file="a1.jag" )

a1.par <- c("mu","fatal[27]")

a1.ini <- list(list( mu=22 ),
              list( mu=23 ),
              list( mu=24 ) )

a1.dat <- list( fatal = c(airline$fatal,NA), I=27 )

# Model compilation and burn-in
a1.mod <- jags.model( file = "a1.jag",
                    data = a1.dat,
                    inits = a1.ini,
                    n.chains = 3,
                    n.adapt = 1000 )
  
# Sampling from the posterior
a1.res <- coda.samples( a1.mod,
                      var = a1.par,
                      n.iter = 10000,
                      thin = 10 )
summary( a1.res )

theta <- rgamma(6000, 634, 26 )
y.2002 <- rpois(6000,theta)
plot( main = 'Posterior predictive distribution of y in 2002',table(y.2002), type="h", lwd=5, lend=2, col=gray(0.2), bty="n", ylab="", xlim=c(5,60) )
tpr <- table( as.matrix( a1.res[,"fatal[27]"] ) )
points( as.numeric(names(tpr))+0.4, tpr, type="h", col="red", lwd=4 )
legend("topright", c('Directly simulated','posterior values from BUGS output'),col=c(gray(0.2),'red'),lwd = 5)


```
## Diagnostics for model 1

```{r}

result = ggs(a1.res)
ggs_density(result)
ggs_traceplot(result)
ggs_running(result)
ggs_autocorrelation(result)

```


## Model 2

A more natural model is the multiplicative one

$$log(E(y(t)|t,m(t))) = \alpha + \beta t + log(m(t))$$

with :

$$y_i \sim Pois(\mu)$$
and 
$$\mu = exp(\alpha + \beta * year ) * miles$$

with uninformative ppriors: 

$\alpha \sim Norm(0,0.000001)$
$\beta \sim Norm(0,0.000001)$


```{r}
summary(glm2 <- glm( fatal ~ I(year-1985) + offset(log(miles)),family=poisson,data=airline)) 
```
which shows that rates decrease about 7% per year.

We can now fit a model using JAGS


```{r}
cat( "model
 {
 for( i in 1:I )
 {
 mu[i] <- exp( alpha + beta*(i-10) ) * miles[i]
 fatal[i] ~ dpois( mu[i] )
 }
 alpha ~ dnorm(0,0.000001)
 beta ~ dnorm(0,0.000001)
 }",
 file="a2.jag" )
 a2.ini <- list( list( alpha=1.0, beta=-0.05 ),
 list( alpha=1.5, beta=-0.06 ),
 list( alpha=0.5, beta=-0.04 ) )
 a2.dat <- list( fatal=c(airline$fatal,NA),
 miles=c(airline$miles,20), I=27 )
 a2.par <- c("alpha","beta","fatal[27]")
 # Model compilation and burn-in
 a2.mod <- jags.model( file = "a2.jag",
 data = a2.dat,
 inits = a2.ini,
 n.chains = 3,
 n.adapt = 1000 )
 # Sampling from the posterior
 a2.res <- coda.samples( a2.mod,
 var = a2.par,
 n.iter = 10000,
 thin = 10 )
 summary( a2.res )
```

```{r}
library( Epi )
ci.lin( glm2)
```
we can see that beta and year  are virtually identical according to the CI seen here and the 95% posterior interval from the bugs simulation


```{r}
result2 = ggs(a2.res)
ggs_density(result2)
ggs_traceplot(result2)
ggs_running(result2)
ggs_autocorrelation(result2)
```

# Model 3

```{r model 3}
library(rjags)
 cat( "model
 {
 for( i in 1:I )
 {
 fatal[i] ~ dpois( mu[i] )
 log(mu[i]) <- alpha + beta*miles[i]+ beta2 * miles[i]*rate[i]
 }
 alpha ~ dnorm(0,0.0001)
 beta ~ dnorm(0.0001,0.00001)
 beta2 ~ dnorm(0.0001,0.00001)
 }",
 
 file="a3.jag" )

 a3.ini= list(
    list(alpha = 0.01, beta = 0.6, beta2=0.1),
    list(alpha = 0.2, beta = 0.2, beta2=0.2),
    list(alpha = 0.7, beta = 0.7, beta2=0.3))
 a3.dat <- list( rate= c(airline$rate,0.7080,0.3,0.4),fatal=c(airline$fatal,NA,NA,NA), miles=c(airline$miles,19.775,23.300,20.3), I=29 )
 a3.par <- c("alpha","beta","beta2","fatal[27]","fatal[28]","fatal[29]")

 # Model compilation and burn-in
 a3.mod <- jags.model(file = "a3.jag",data = a3.dat,inits = a3.ini,n.chains = 3,n.adapt = 1000)
 update(a3.mod,1000)
 # Sampling from the posterior
 a33.res <- coda.samples( a3.mod,var = a3.par,n.iter = 10000,thin = 50 )
 summary( a33.res )
 #predictions
``` 
## fernando

```{r model fern}
library(rjags)
 cat( "model
 {
 for( i in 1:I )
 {
 fatal[i] ~ dpois( mu[i] )
 log(mu[i]) <- alpha + beta2 * miles[i]*rate[i]
 }
 alpha ~ dnorm(0,0.0001)
 
 beta2 ~ dnorm(0.0001,0.00001)
 }",
 
 file="a3.jag" )

 a3.ini= list(
    list(alpha = 0.01, beta2=0.1),
    list(alpha = 0.2, beta2=0.2),
    list(alpha = 0.7,  beta2=0.3))
 a3.dat <- list( rate= c(airline$rate,0.7080,0.3,0.4),fatal=c(airline$fatal,NA,NA,NA), miles=c(airline$miles,19.775,23.300,20.3), I=29 )
 a3.par <- c("alpha","beta2","fatal[27]","fatal[28]","fatal[29]")

 # Model compilation and burn-in
 a3.mod <- jags.model(file = "a3.jag",data = a3.dat,inits = a3.ini,n.chains = 3,n.adapt = 1000)
 update(a3.mod,1000)
 # Sampling from the posterior
 a3.res <- coda.samples( a3.mod,var = a3.par,n.iter = 10000,thin = 50 )
 summary( a3.res )
 #predictions
``` 
 

```{r}
result3 = ggs(a3.res)
ggs_density(result3)
ggs_traceplot(result3)
ggs_running(result3)
ggs_autocorrelation(result3)
```

# Model 4 test

```{r model 4}
library(rjags)
 cat( "model
 {
 for( i in 1:I )
 {
 fatal[i] ~ dnorm( mu[i],1/mu[i] )
 mu[i] <- alpha + beta2 * miles[i]
 }
 alpha ~ dnorm(0,0.0001)
 beta2 ~ dnorm(0,0.0001)
 }",
 file="a4.jag" )

 a4.ini= list(
    list(alpha = 0.01, beta2=3),
    list(alpha = 0.2, beta2=1),
    list(alpha = 0.7, beta2=2))
 a4.dat <- list( rate = c(airline$rate,0.7080,0.3),fatal=c(airline$fatal,NA,NA), miles=c(airline$miles,19.775,23.300), I=28 )
 a4.par <- c("alpha","beta2","fatal[27]","fatal[28]")

 # Model compilation and burn-in
 a4.mod <- jags.model(file = "a4.jag",data = a4.dat,inits = a4.ini,n.chains = 3,n.adapt = 1000 )
 # Sampling from the posterior
 update(a4.mod,1000)
 a4.res <- coda.samples( a4.mod,var = a4.par,n.iter = 3000,thin = 10 )
 summary( a4.res )
 #predictions
``` 
```{r}
result4 = ggs(a4.res)
ggs_density(result4)
ggs_traceplot(result4)
ggs_running(result4)
ggs_autocorrelation(result4)
```

```{r}
 a3.m <- as.matrix(a33.res)
log.enum.2002 <- a3.m[,"alpha"] + a3.m[,"beta"]*19.775
#print(exp(log.enum.2002))
summary( exp(log.enum.2002 ))
v =exp(log.enum.2002 )
#plot(density(v))
(e2002.qnt <- quantile( v, probs=c(50,2.5,97.5)/100))
plot( density(v), type="l", lwd=2, col= "red" )
abline( c=e2002.qnt)
```


## Prediction

We want to predict the expected number of airlines fatalities in 2002 (assuming that the amount of miles flown is $ 20\times 10^{12}$ ), so we need the posterior of $exp( \alpha + \beta \times (2002-1985))\times 20$
```{r}
a2.m <- as.matrix(a2.res)
enum.2002 <- exp(a2.m[,"alpha"] + a2.m[,"beta"]*17)*20
summary( enum.2002 )
(e2002.qnt <- quantile( enum.2002, probs=c(50,2.5,97.5)/100))
plot( density(enum.2002), type="l", lwd=2, col= "red" )
abline( v=e2002.qnt)
```

The node fatal[27] contains the predictive distribution for the number of fatal
accidents in 2002.
Its posterior mean is 20.04 (similar to that for the expected
number of fatal accidents in 2002) with a standard deviation of 4.864 and 95%
interval [11,30]
We can plot its distribution.
```{r}
plot( table(a2.m[,"fatal[27]"]), type="h", lwd=5, lend=2, col=gray(0.5), bty="n", ylab="" )
```

We can notice from the table of true values bolow that our prediction of 20 for the number of fatal accidents in 2002 was wrong as the right one was 14 but still fits well within the prediction interval of (11,30).
Finally we notice also that, since 1976, the rate of fatal accident per air mile flown has decreased becoming ten times lower.




      Year      Fatal accidents   Passenger miles    Accident rate
                   

      2002      14                19.775             0.7080
      2003      7                 23.300             0.3004
      2004      9                 20.300             0.4433

## Model comparison throughout DIC index
A good way to select the model that fits best our data, is using the DIC measure.
The DIC (deviance information criterion) is a Bayesian criterion for model comparison, defined as:
$$ DIC = D(\bar{\theta}) + 2_{p_D}$$
 Where: 
      $D(\theta) = -2logL(\theta)$,
      $p_D = \bar D - D(\bar \theta)$, is the effective number of paramenters of the model, the larger $p_D$ the easier the model fits on the data.
      $\bar D = E[D(\theta)]$, its the mean deviance. is a measure of how well the model fits the data, the larger the worse the fit.
      $D(\bar \theta) = D[E(\theta)]$
      
the basic idea is that the models with smaller DIC should be preferred.
Models are penalized both by the value of $\bar D$, which favors a good fit, but also by the effective number of parameters $p_D$.
Since $\bar D$ will decrease as the number of parameters in a model increases, the $p_{D}$ term compensates for this effect by favoring models with a smaller number of parameters.
```{r}
#Model Comparison
DICmod1 = dic.samples(a1.mod, n.iter=10000, thin=10, type="pD")
DICmod2 = dic.samples(a2.mod, n.iter=10000, thin =10, type="pD")
print('model 1 DIC')
DICmod1
print('model 2 DIC')
DICmod2
```

